{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rockpool in /home/alessandro/tesi/tesi-python/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: scipy in /home/alessandro/tesi/tesi-python/lib/python3.10/site-packages (from rockpool) (1.9.3)\n",
      "Requirement already satisfied: numpy in /home/alessandro/tesi/tesi-python/lib/python3.10/site-packages (from rockpool) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rockpool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from snntorch import spikeplot as splt\n",
    "from rockpool.nn.modules import LinearTorch, LIFTorch\n",
    "from rockpool.nn.combinators import Sequential\n",
    "from rockpool.parameters import Constant\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download del datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader arguments\n",
    "data_root='../data'\n",
    "# Device and data repository\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasformazioni da applicare al Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "fmnist_train = datasets.FashionMNIST(data_root, train=True, download=True, transform=transform)\n",
    "fmnist_test = datasets.FashionMNIST(data_root, train=False, download=True, transform=transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definizione della dimensione del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione dei dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(fmnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "# Targets dictionary\n",
    "target_label = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "lib = \"rockpool\"\n",
    "\n",
    "def plot_data_spike_recording(spk_rec, batch_size, targets, data, index=0):\n",
    "    for i in range(0,batch_size):\n",
    "        item_type = target_label[targets[i].item()].lower().replace(' ','-').replace('/', '-')\n",
    "        save_path = \"../figures/classifications/{}/{}\".format(\n",
    "            lib,\n",
    "            target_label[targets[i].item()].lower().replace(' ','-').replace('/', '-'),\n",
    "        )\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        fig = plt.figure(figsize=(16, 9))\n",
    "        bx, ax = fig.subplots(ncols=2)\n",
    "        ax.set_xlim((-1,110))\n",
    "        ax.set_ylim((-1,10))\n",
    "        ax.set_yticks(range(0,10), target_label.items())\n",
    "        ss = spk_rec[i,:,:]\n",
    "        splt.raster(ss, ax, s=1, c=\"black\")\n",
    "\n",
    "        plt.title(\"Classification - {} - {}\".format(target_label[targets[i].item()], targets[i]))\n",
    "        plt.xlabel(\"Time step\")\n",
    "        plt.ylabel(\"Neuron Number, Item class\")\n",
    "\n",
    "        bx.set_title(target_label[targets[i].item()])\n",
    "        bx.set_xticks([], None)\n",
    "        bx.set_yticks([], None)\n",
    "        bx.imshow(data[i].squeeze().detach())\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(\n",
    "            \"{}/{}-{}.eps\".format(\n",
    "                save_path,\n",
    "                target_label[targets[i].item()].lower().replace(' ','-').replace('/', '-'),\n",
    "                (index*batch_size)+i\n",
    "            ),\n",
    "            format='eps'\n",
    "        )\n",
    "        fig.savefig(\n",
    "            \"{}/{}-{}.png\".format(\n",
    "                save_path,\n",
    "                target_label[targets[i].item()].lower().replace(' ','-').replace('/', '-'),\n",
    "                (index*batch_size)+i\n",
    "            ),\n",
    "            format='png'\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architettura e dinamica temporale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "# num_hidden = 1000\n",
    "num_hidden = 512\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 100\n",
    "dt = 1e-2\n",
    "tau_mem = Constant(100e-3)\n",
    "tau_syn = Constant(50e-3)\n",
    "threshold = Constant(1.)\n",
    "bias = Constant(0.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Encode del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Define a function to encode an input into a poisson event series\n",
    "def encode_poisson(data: torch.Tensor, num_steps: int, scale: float = 0.1) -> torch.Tensor:\n",
    "    num_batches, _, _ = data.shape\n",
    "    data = scale * data.view((num_batches, 1, -1)).repeat((1, num_steps, 1))\n",
    "    return (torch.rand(data.shape) < (data * scale)).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode in spike degli obiettivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Define a function to encode the network target\n",
    "def encode_class(class_idx: torch.Tensor, num_classes: int, num_steps: int) -> torch.Tensor:\n",
    "    num_batches = class_idx.numel()\n",
    "    target = torch.nn.functional.one_hot(class_idx, num_classes = num_classes)\n",
    "    return target.view((num_batches, 1, -1)).repeat((1, num_steps, 1)).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "def DefineNet(num_inputs, num_hidden, num_outputs):\n",
    "    return Sequential(\n",
    "        LinearTorch((num_inputs, num_hidden)),\n",
    "        LIFTorch(\n",
    "            num_hidden,\n",
    "            tau_mem=tau_mem,\n",
    "            tau_syn=tau_syn,\n",
    "            threshold=threshold,\n",
    "            bias=bias,\n",
    "            dt=dt\n",
    "        ),\n",
    "        LinearTorch((num_hidden, num_outputs)),\n",
    "        LIFTorch(\n",
    "            num_outputs,\n",
    "            tau_mem=tau_mem,\n",
    "            tau_syn=tau_syn,\n",
    "            threshold=threshold,\n",
    "            bias=bias,\n",
    "            dt=dt\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchSequential  with shape (784, 10) {\n",
       "    LinearTorch '0_LinearTorch' with shape (784, 512)\n",
       "    LIFTorch '1_LIFTorch' with shape (512, 512)\n",
       "    LinearTorch '2_LinearTorch' with shape (512, 10)\n",
       "    LIFTorch '3_LIFTorch' with shape (10, 10)\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network instantiation\n",
    "net = DefineNet(num_inputs=num_inputs, num_hidden=num_hidden, num_outputs=num_outputs)\n",
    "net.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train = False\n",
    "state_dict_file_path = \"../models/Rockpool-FMNIST-training.pt\"\n",
    "\n",
    "try:\n",
    "    load_state_dict = torch.load( state_dict_file_path, map_location=device, )\n",
    "    net.load_state_dict(load_state_dict)\n",
    "except FileNotFoundError:\n",
    "    print( \"File not found running training\" )\n",
    "    run_train = True\n",
    "\n",
    "if ( run_train == True ):\n",
    "    print(\"Run the Rockpool-FMNIST-training.ipynb first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(fmnist_test, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "  net.eval()\n",
    "  for data, targets in test_loader:\n",
    "    enc_data = encode_poisson(data.squeeze(), num_steps)\n",
    "    enc_targets = encode_class(targets, 10, num_steps)\n",
    "    enc_targets = targets.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    test_spk, _, _ = net(enc_data.to(device))\n",
    "\n",
    "    plot_data_spike_recording(spk_rec=test_spk, batch_size=batch_size, targets=targets, data=data, index=index)\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
